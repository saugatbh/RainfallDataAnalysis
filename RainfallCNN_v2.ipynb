{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RainfallCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xv32FXbI9rU4ZI20pnusqceZOc9Ghdym",
      "authorship_tag": "ABX9TyNkQDl+f3A6Lxa2LOHkO+3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saugatbh/RainfallDataAnalysis/blob/main/RainfallCNN_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3uNsbeQGn6p"
      },
      "source": [
        "**Read 114 images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsYHZWeyMXmo"
      },
      "source": [
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "path='/content/drive/MyDrive/RainfallDataAnalysis-main/ModifiedFiguresAnnualAvg'\n",
        "images=[]\n",
        "for filename in os.listdir(path):\n",
        "  img = cv2.imread(os.path.join(path,filename))\n",
        "  if img is not None:\n",
        "    images.append(img)\n",
        "images=np.array(images)\n",
        "images = images.astype('float32')\n",
        "images /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MkDVivfG8X5"
      },
      "source": [
        "**Define CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF64L8n_ej16"
      },
      "source": [
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(50,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu',input_shape=(656,875,3)))\n",
        "  model.add(Conv2D(75,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Conv2D(125,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  \n",
        "  model.add(Dense(500,activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(250,activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcdEYH1jHD2t"
      },
      "source": [
        "**Split training and testing** <br>\n",
        "Last 14 images for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joqef8DMSue-"
      },
      "source": [
        "def train_test_split(data,ntest):\n",
        "  print(\"splitting data\")\n",
        "  return data[:ntest], data[-ntest:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Uq93G8AHwir"
      },
      "source": [
        "**Series to Supervised**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sa8dXwChQit"
      },
      "source": [
        "def split_data(images, nstep=15):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(images)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + nstep\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(images)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = images[i:end_ix], images[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def series_to_supervised(data, n_in, n_out=1):\n",
        "      \n",
        "    df = pd.DataFrame(data)\n",
        "    print(df.describe)\n",
        "    cols = list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    # drop rows with NaN values\n",
        "    agg.dropna(inplace=True)\n",
        "    print('converted data is ----------')\n",
        "    print(agg.values)\n",
        "    agg = np.array(agg).reshape(n_in,656,875,3)\n",
        "    return agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvWYRpqSH7u2"
      },
      "source": [
        "**Model Fit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYtDgzQFhfXA"
      },
      "source": [
        "def measure_rmse(actual, predicted):\n",
        "    return sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# fit a model\n",
        "def model_fit(train):\n",
        "    print(\"here in model fit\")\n",
        "    # prepare data\n",
        "    data = series_to_supervised(train, 5)\n",
        "    #train_x, train_y = split_data(train,nstep=15)\n",
        "    train_x, train_y = data[:, :-1], data[:, -1]\n",
        "    print(\"done to supervised\")\n",
        "    print(train_x.shape,train_y.shape)\n",
        "    # define model\n",
        "    model = define_model()\n",
        "    # fit\n",
        "    model.fit(train_x, train_y, epochs=10, batch_size=128, verbose=0)\n",
        "    return model\n",
        "\n",
        "# forecast with a pre-fit model\n",
        "def model_predict(model, history):\n",
        "    # prepare data\n",
        "    print(\"here in predict\")\n",
        "    x_input = array(history[-5:]).reshape(1, 5)\n",
        "    # forecast\n",
        "    yhat = model.predict(x_input, verbose=0)\n",
        "    return yhat[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_L1mlxrIAjG"
      },
      "source": [
        "**Walk forward validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fanG_MxbQIlZ"
      },
      "source": [
        "def walk_forward_validation(data,n_test):\n",
        "  print(\"here in walk\")\n",
        "  predictions = list()\n",
        "  train, test = train_test_split(data, n_test)\n",
        "  print(type(train))\n",
        "  print(train.shape)\n",
        "  print(test.shape)\n",
        "  model = model_fit(train)\n",
        "  history = [x for x in train]\n",
        "  for i in range(len(test)):\n",
        "    yhat = model_predict(model, history)\n",
        "    predictions.append(yhat)\n",
        "    history.append(test[i])\n",
        "  error = measure_rmse(test, predictions)\n",
        "  print(' > %.3f' % error)\n",
        "  return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GdlwkItIJ1O"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0UQREzYNKEN"
      },
      "source": [
        "def repeat_evaluate(data, n_test, n_repeats=3):\n",
        "  \n",
        "  print('here!')\n",
        "  print(data.shape)\n",
        "  data = data.reshape(data.shape[0],(656*875*3))\n",
        "  scores = [walk_forward_validation(data, n_test) for _ in range(n_repeats)]\n",
        "  scores_m, score_std = np.mean(scores), np.std(scores)\n",
        "  print('%s: %.3f RMSE (+/- %.3f)' % (scores_m, score_std))\n",
        "  pyplot.boxplot(scores)\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK0vL-U4ITwe"
      },
      "source": [
        "**Main Function call**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RzxBJ_0dRzz"
      },
      "source": [
        "n_test=14\n",
        "repeat_evaluate(images,n_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}